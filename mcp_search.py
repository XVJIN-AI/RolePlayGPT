"""
MCP (Model Context Protocol) æœç´¢å¢å¼ºæ¨¡å—
æ™ºèƒ½åˆ¤æ–­å¹¶æ‰§è¡Œç½‘ç»œæœç´¢ï¼Œä¸ºè§’è‰²å¯¹è¯æä¾›çœŸå®èƒŒæ™¯èµ„æ–™
"""
import re
import json
from typing import List, Dict, Optional
try:
    from ddgs import DDGS  # æ–°ç‰ˆæœ¬çš„åŒ…å
except ImportError:
    try:
        from duckduckgo_search import DDGS  # å‘åå…¼å®¹æ—§ç‰ˆæœ¬
    except ImportError:
        raise ImportError("è¯·å®‰è£…æœç´¢åŒ…: pip install ddgs")
import requests
from bs4 import BeautifulSoup
from openai import OpenAI


class MCPSearchEngine:
    """MCPæœç´¢å¼•æ“ - æ™ºèƒ½åˆ¤æ–­å¹¶æ‰§è¡Œç½‘ç»œæœç´¢"""
    
    def __init__(self, client: OpenAI):
        self.client = client
        self.ddgs = DDGS()
        
    def should_search(self, user_message: str, character_name: str) -> Dict:
        """
        ä½¿ç”¨GPTåˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œç½‘ç»œæœç´¢
        
        å‚æ•°:
            user_message: ç”¨æˆ·çš„é—®é¢˜
            character_name: å½“å‰è§’è‰²åç§°
            
        è¿”å›:
            {
                "need_search": bool,
                "search_query": str,
                "reason": str
            }
        """
        decision_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ¤æ–­ç”¨æˆ·çš„é—®é¢˜æ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢æ¥å¢å¼ºå›ç­”ã€‚

è§’è‰²ï¼š{character_name}
ç”¨æˆ·é—®é¢˜ï¼š{user_message}

è¯·åˆ¤æ–­ä»¥ä¸‹æƒ…å†µæ˜¯å¦éœ€è¦æœç´¢ï¼š
1. æ¶‰åŠå…·ä½“çš„å†å²äº‹ä»¶ã€æ•…äº‹æƒ…èŠ‚ç»†èŠ‚
2. æåˆ°åŸè‘—ä¸­çš„å…·ä½“åœºæ™¯ã€å¯¹è¯
3. è¯¢é—®è§’è‰²èƒŒæ™¯æ•…äº‹çš„è¯¦ç»†å†…å®¹
4. éœ€è¦å¼•ç”¨åŸä½œå†…å®¹çš„é—®é¢˜
5. è¯¢é—®å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚ã€ä¸“ä¸šçŸ¥è¯†

å¦‚æœéœ€è¦æœç´¢ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªç²¾ç¡®çš„æœç´¢å…³é”®è¯ï¼ˆä¼˜å…ˆä¸­æ–‡ï¼‰ã€‚

è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
{{
    "need_search": true/false,
    "search_query": "æœç´¢å…³é”®è¯",
    "reason": "åˆ¤æ–­ç†ç”±"
}}"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹åšåˆ¤æ–­
                messages=[{"role": "user", "content": decision_prompt}],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            print(f"MCPå†³ç­–å¤±è´¥: {e}")
            return {"need_search": False, "search_query": "", "reason": "å†³ç­–å¤±è´¥"}
    
    def search_web(self, query: str, max_results: int = 5) -> List[Dict]:
        """
        ä½¿ç”¨DuckDuckGoæœç´¢ç½‘ç»œå†…å®¹
        
        å‚æ•°:
            query: æœç´¢å…³é”®è¯
            max_results: æœ€å¤§ç»“æœæ•°
            
        è¿”å›:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            results = []
            print(f"ğŸ” å¼€å§‹æœç´¢: {query}")
            
            # å°è¯•å¤šç§æœç´¢ç­–ç•¥
            search_strategies = [
                {'region': None, 'safesearch': 'moderate'},  # å…ˆä¸æŒ‡å®šregion
                {'region': 'wt-wt', 'safesearch': 'moderate'},  # å…¨çƒ
                {'region': 'cn-zh', 'safesearch': 'off'},  # ä¸­å›½åŒºï¼Œå…³é—­å®‰å…¨æœç´¢
            ]
            
            for i, strategy in enumerate(search_strategies):
                try:
                    print(f"  ç­–ç•¥ {i+1}: region={strategy['region']}, safesearch={strategy['safesearch']}")
                    
                    search_params = {
                        'keywords': query,
                        'max_results': max_results,
                        'safesearch': strategy['safesearch']
                    }
                    if strategy['region']:
                        search_params['region'] = strategy['region']
                    
                    # æ³¨æ„ï¼šæ–°ç‰ˆddgsåŒ…çš„APIå¯èƒ½æœ‰å˜åŒ–
                    search_results = self.ddgs.text(**search_params)
                    
                    # å°†ç”Ÿæˆå™¨è½¬æ¢ä¸ºåˆ—è¡¨
                    search_results_list = list(search_results) if search_results else []
                    
                    if search_results_list:
                        for r in search_results_list:
                            results.append({
                                'title': r.get('title', ''),
                                'snippet': r.get('body', ''),
                                'url': r.get('href', '')
                            })
                        print(f"  âœ… æˆåŠŸï¼æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
                        break  # æˆåŠŸå°±é€€å‡º
                    else:
                        print(f"  âŒ ç­–ç•¥ {i+1} è¿”å›ç©ºç»“æœï¼Œå°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥")
                        
                except Exception as strategy_error:
                    print(f"  âŒ ç­–ç•¥ {i+1} å¤±è´¥: {strategy_error}")
                    continue
            
            if not results:
                print("âš ï¸ æ‰€æœ‰æœç´¢ç­–ç•¥éƒ½æœªèƒ½æ‰¾åˆ°ç»“æœ")
            
            return results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def summarize_search_results(self, query: str, results: List[Dict]) -> str:
        """
        ä½¿ç”¨GPTæ€»ç»“æœç´¢ç»“æœ
        
        å‚æ•°:
            query: æœç´¢å…³é”®è¯
            results: æœç´¢ç»“æœåˆ—è¡¨
            
        è¿”å›:
            æ€»ç»“æ–‡æœ¬
        """
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
        
        # æ„å»ºæœç´¢ç»“æœæ–‡æœ¬
        results_text = "\n\n".join([
            f"æ¥æº {i+1}ï¼š{r['title']}\n{r['snippet']}"
            for i, r in enumerate(results[:3])  # åªç”¨å‰3ä¸ªç»“æœ
        ])
        
        summary_prompt = f"""è¯·æ€»ç»“ä»¥ä¸‹å…³äº"{query}"çš„æœç´¢ç»“æœï¼Œæå–å…³é”®ä¿¡æ¯ï¼š

{results_text}

è¦æ±‚ï¼š
1. åªæå–ä¸é—®é¢˜ç›´æ¥ç›¸å…³çš„äº‹å®ä¿¡æ¯
2. ä¿æŒå®¢è§‚ï¼Œä¸æ·»åŠ ä¸ªäººè§‚ç‚¹
3. ç”¨ç®€æ´çš„è¯­è¨€ï¼Œ3-5å¥è¯æ¦‚æ‹¬
4. å¦‚æœä¿¡æ¯æœ‰çŸ›ç›¾ï¼ŒæŒ‡å‡ºä¸åŒè¯´æ³•
5. ä¿æŒä¸­æ–‡è¾“å‡º"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": summary_prompt}],
                temperature=0.3,
                max_tokens=500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"æ€»ç»“å¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šç›´æ¥è¿”å›å‰3ä¸ªç»“æœçš„æ‘˜è¦
            return "\n".join([r['snippet'][:200] for r in results[:3]])
    
    def enhance_context(self, 
                       user_message: str, 
                       character_name: str,
                       search_results_summary: str) -> str:
        """
        ç”Ÿæˆå¢å¼ºçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        å‚æ•°:
            user_message: ç”¨æˆ·é—®é¢˜
            character_name: è§’è‰²åç§°
            search_results_summary: æœç´¢ç»“æœæ€»ç»“
            
        è¿”å›:
            å¢å¼ºçš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        enhanced_context = f"""
ã€èƒŒæ™¯çŸ¥è¯†å¢å¼ºã€‘
ç”¨æˆ·è¯¢é—®ï¼š{user_message}

ç›¸å…³èƒŒæ™¯èµ„æ–™ï¼ˆæ¥è‡ªç½‘ç»œæœç´¢ï¼‰ï¼š
{search_results_summary}

è¯·åŸºäºä»¥ä¸ŠçœŸå®èµ„æ–™ï¼Œç»“åˆè§’è‰²{character_name}çš„èº«ä»½å’Œç»å†ï¼Œç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚
æ³¨æ„ï¼š
1. ä¼˜å…ˆä½¿ç”¨æœç´¢åˆ°çš„çœŸå®ä¿¡æ¯
2. ä¿æŒè§’è‰²çš„è¯­è¨€é£æ ¼å’Œæ€§æ ¼ç‰¹ç‚¹
3. å¦‚æœæœç´¢ç»“æœä¸å……åˆ†ï¼Œå¯ä»¥åŸºäºè§’è‰²è®¾å®šè¿›è¡Œåˆç†æ¨æµ‹ï¼Œä½†è¦è¯´æ˜
4. è‡ªç„¶åœ°å°†èƒŒæ™¯çŸ¥è¯†èå…¥å›ç­”ä¸­ï¼Œä¸è¦ç”Ÿç¡¬åœ°ç…§æ¬"""
        return enhanced_context


class MCPChatManager:
    """æ•´åˆMCPæœç´¢çš„å¯¹è¯ç®¡ç†å™¨"""
    
    def __init__(self, openai_client: OpenAI):
        self.client = openai_client
        self.search_engine = MCPSearchEngine(openai_client)
        self.search_cache = {}  # ç¼“å­˜æœç´¢ç»“æœ
    
    def chat_with_mcp(self, 
                      user_message: str,
                      character: Dict,
                      system_prompt: str,
                      conversation_history: List[Dict],
                      enable_search: bool = True,
                      model: str = "gpt-4o-ca",
                      temperature: float = 0.8,
                      max_tokens: int = 2000) -> Dict:
        """
        å¸¦MCPæœç´¢å¢å¼ºçš„å¯¹è¯
        
        å‚æ•°:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            character: è§’è‰²ä¿¡æ¯å­—å…¸
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            conversation_history: å¯¹è¯å†å²
            enable_search: æ˜¯å¦å¯ç”¨æœç´¢
            model: ä½¿ç”¨çš„æ¨¡å‹
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        è¿”å›:
            {
                "response": str,
                "tokens_used": int,
                "cost": float,
                "search_performed": bool,
                "search_query": str,
                "search_summary": str,
                "search_results": List[Dict]
            }
        """
        result = {
            "response": "",
            "tokens_used": 0,
            "cost": 0.0,
            "search_performed": False,
            "search_query": "",
            "search_summary": "",
            "search_results": []
        }
        
        # 1. MCPå†³ç­–ï¼šæ˜¯å¦éœ€è¦æœç´¢
        if enable_search:
            decision = self.search_engine.should_search(
                user_message, 
                character['name']
            )
            
            if decision['need_search']:
                search_query = decision['search_query']
                print(f"ğŸ” MCPè§¦å‘æœç´¢: {search_query}")
                
                # æ£€æŸ¥ç¼“å­˜
                if search_query in self.search_cache:
                    search_summary = self.search_cache[search_query]['summary']
                    search_results = self.search_cache[search_query]['results']
                    print("ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„æœç´¢ç»“æœ")
                else:
                    # 2. æ‰§è¡Œæœç´¢
                    search_results = self.search_engine.search_web(search_query)
                    
                    if search_results:
                        # 3. æ€»ç»“æœç´¢ç»“æœ
                        search_summary = self.search_engine.summarize_search_results(
                            search_query, 
                            search_results
                        )
                        
                        # ç¼“å­˜ç»“æœ
                        self.search_cache[search_query] = {
                            'summary': search_summary,
                            'results': search_results
                        }
                        print(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} æ¡ç»“æœ")
                    else:
                        search_summary = "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
                        search_results = []
                        print("âŒ æœç´¢æ— ç»“æœ")
                
                # 4. å¢å¼ºç³»ç»Ÿæç¤ºè¯
                enhanced_context = self.search_engine.enhance_context(
                    user_message,
                    character['name'],
                    search_summary
                )
                
                system_prompt = f"{system_prompt}\n\n{enhanced_context}"
                
                result['search_performed'] = True
                result['search_query'] = search_query
                result['search_summary'] = search_summary
                result['search_results'] = search_results
        
        # 5. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        messages.extend(conversation_history)
        messages.append({"role": "user", "content": user_message})
        
        # 6. è°ƒç”¨GPTç”Ÿæˆå›å¤
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            result['response'] = response.choices[0].message.content
            result['tokens_used'] = response.usage.total_tokens
            
            # è®¡ç®—è´¹ç”¨ï¼ˆgpt-4o-caå®šä»·ï¼‰
            prompt_tokens = response.usage.prompt_tokens
            completion_tokens = response.usage.completion_tokens
            result['cost'] = (prompt_tokens * 0.000005 + 
                            completion_tokens * 0.000015)
            
        except Exception as e:
            print(f"GPTè°ƒç”¨å¤±è´¥: {e}")
            result['response'] = f"æŠ±æ­‰ï¼Œå›å¤ç”Ÿæˆå¤±è´¥ï¼š{str(e)}"
        
        return result

